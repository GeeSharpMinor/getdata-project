{
    "contents" : "## Download and unzip the data.\nurl = \"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip\";\ndownload.file(url=url, destfile = \"project.zip\", mode=\"wb\");\nunzip(zipfile = \"project.zip\");\n\n## Save the current working directory.  We will return to this later when we output the tidy dataset\nhome = getwd();\n\n## After unziping, the contents of the zipfile are placed in the \"UCI HAR Dataset\" subfolder.  \n## Set that folder as the working directory\nsetwd(\"./UCI HAR Dataset\");\n\n## Read in the column names for the X data files.  These variable names are stored under \"features.txt\" from the original data\ncolNames <- read.delim(\"features.txt\", sep=\" \", header=FALSE, col.names = c(\"col.num\", \"variable.name\"),\n                       stringsAsFactors=FALSE);\ncolNames <- colNames$variable.name;\n\n## Load the measurement \"X\" data from the training and test sets, then combine them into X.\nw <- rep(16, length(colNames));\nX.test <- read.fwf(file=\"./test/X_test.txt\", widths=w, colClasses=\"numeric\", buffersize=100);\nX.train <- read.fwf(file=\"./train/X_train.txt\", widths=w, colClasses=\"numeric\", buffersize=100);\nX <- rbind(X.test, X.train);\n\n## Remove the individual sets from memory\nremove(\"X.test\",\"X.train\");\n\n\n\n## Add column names to X and keep only those columns that calculate \n## the mean or standard deviation of a measurement by searching for those terms with grep\nnames(X) = colNames;\nidx.keep <- grep(x=colNames,pattern=\"mean()\",fixed=TRUE);\nidx.keep <-c(idx.keep,grep(x=colNames,pattern=\"std()\", fixed=TRUE));\nX <- X[,idx.keep];\n\n## For each row in the measurement X data, there is an indicator for the type of activity.  Load the test and training\n## data, then combine them.\nactivity.test <- read.table(file=\"./test/y_test.txt\", header=FALSE, stringsAsFactors=FALSE);\nactivity.train <- read.table(file=\"./train/y_train.txt\", header=FALSE, stringsAsFactors=FALSE);\nactivity <- rbind(activity.test, activity.train);\n\n## Read in the corresponding description for each activity code.\nactivity_labels <- read.delim(\"activity_labels.txt\", sep=\" \", header=FALSE, \n                              col.names=c(\"code\", \"activity.name\"), stringsAsFactors=FALSE);\n\n## Replace activity codes for each line of X with readable descriptions\nactivity <- merge(x=activity, y=activity_labels, by.x=\"V1\", by.y=\"code\");\nactivity <- activity[,2];\n\n## Load and combine the subject information for each line in X\nsubject_test <- read.table(file=\"./test/subject_test.txt\", header=FALSE, stringsAsFactors=FALSE);\nsubject_train <- read.table(file=\"./train/subject_train.txt\", header=FALSE, stringsAsFactors=FALSE);\nsubject <- rbind(subject_test, subject_train);\n\n\n## Merge the subject ids, the activity names, and the mean and std data\nX <- cbind(subject, activity, X);\nnames(X)[1] <- \"subject.id\";\n\n## Create a second, independent tidy data set with the average of each variable for each activity and each subject.\nlibrary(plyr);\nlibrary(reshape2)\n\nXmelted <- melt(X, id.vars=c(\"subject.id\", \"activity\"));\n#Xsummarized <- ddply(Xmelted, .(subject.id, activity, variable), summarize, mean=mean(value));\n\ntidy_data <- dcast(Xmelted, subject.id + activity~variable, fun.aggregate=mean);\n\ntidy_data <- arrange(tidy_data, subject.id, activity);\n\n## Go back to the original directory and write out csv tables\nsetwd(home);\nwrite.csv(x=X, file=\"measurement_data.csv\", row.names=FALSE);\nwrite.csv(x=tidy_data, file=\"tidy_data.csv\", row.names=FALSE);\n\n\n\n\n\n",
    "created" : 1402586682989.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3791251609",
    "id" : "92EBD3D8",
    "lastKnownWriteTime" : 1402586687,
    "path" : "~/GitHub/getdata-project/run_analysis.R",
    "project_path" : "run_analysis.R",
    "properties" : {
    },
    "source_on_save" : true,
    "type" : "r_source"
}